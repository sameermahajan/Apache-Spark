{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "from pyspark.sql import SQLContext\n",
    "sqlCtx = SQLContext(sc)\n",
    "df = sqlCtx\\\n",
    "  .read\\\n",
    "  .option(\"inferSchema\", \"true\")\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .csv('file:///home/devuser1/online-retail-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['InvoiceNo',\n",
       " 'StockCode',\n",
       " 'Description',\n",
       " 'Quantity',\n",
       " 'InvoiceDate',\n",
       " 'UnitPrice',\n",
       " 'CustomerID',\n",
       " 'Country']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(InvoiceNo,StringType,true),StructField(StockCode,StringType,true),StructField(Description,StringType,true),StructField(Quantity,IntegerType,true),StructField(InvoiceDate,StringType,true),StructField(UnitPrice,DoubleType,true),StructField(CustomerID,IntegerType,true),StructField(Country,StringType,true)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(InvoiceNo=u'536365', StockCode=u'85123A', Description=u'WHITE HANGING HEART T-LIGHT HOLDER', Quantity=6, InvoiceDate=u'12/1/2010 8:26', UnitPrice=2.55, CustomerID=17850, Country=u'United Kingdom'),\n",
       " Row(InvoiceNo=u'536365', StockCode=u'71053', Description=u'WHITE METAL LANTERN', Quantity=6, InvoiceDate=u'12/1/2010 8:26', UnitPrice=3.39, CustomerID=17850, Country=u'United Kingdom'),\n",
       " Row(InvoiceNo=u'536365', StockCode=u'84406B', Description=u'CREAM CUPID HEARTS COAT HANGER', Quantity=8, InvoiceDate=u'12/1/2010 8:26', UnitPrice=2.75, CustomerID=17850, Country=u'United Kingdom'),\n",
       " Row(InvoiceNo=u'536365', StockCode=u'84029G', Description=u'KNITTED UNION FLAG HOT WATER BOTTLE', Quantity=6, InvoiceDate=u'12/1/2010 8:26', UnitPrice=3.39, CustomerID=17850, Country=u'United Kingdom'),\n",
       " Row(InvoiceNo=u'536365', StockCode=u'84029E', Description=u'RED WOOLLY HOTTIE WHITE HEART.', Quantity=6, InvoiceDate=u'12/1/2010 8:26', UnitPrice=3.39, CustomerID=17850, Country=u'United Kingdom')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(5).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## handle missing values and extract day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format, col, unix_timestamp\n",
    "\n",
    "prepped_df = df\\\n",
    "    .na.fill(0)\\\n",
    "    .withColumn(\"day_of_week\", date_format(unix_timestamp(col(\"InvoiceDate\"), \n",
    "                                                          \"MM/dd/yyyy HH:mm\").cast('timestamp'), \"EEEE\"))\\\n",
    "    .coalesce(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(InvoiceNo=u'536365', StockCode=u'85123A', Description=u'WHITE HANGING HEART T-LIGHT HOLDER', Quantity=6, InvoiceDate=u'12/1/2010 8:26', UnitPrice=2.55, CustomerID=17850, Country=u'United Kingdom', day_of_week=u'Wednesday'),\n",
       " Row(InvoiceNo=u'536365', StockCode=u'71053', Description=u'WHITE METAL LANTERN', Quantity=6, InvoiceDate=u'12/1/2010 8:26', UnitPrice=3.39, CustomerID=17850, Country=u'United Kingdom', day_of_week=u'Wednesday'),\n",
       " Row(InvoiceNo=u'536365', StockCode=u'84406B', Description=u'CREAM CUPID HEARTS COAT HANGER', Quantity=8, InvoiceDate=u'12/1/2010 8:26', UnitPrice=2.75, CustomerID=17850, Country=u'United Kingdom', day_of_week=u'Wednesday'),\n",
       " Row(InvoiceNo=u'536365', StockCode=u'84029G', Description=u'KNITTED UNION FLAG HOT WATER BOTTLE', Quantity=6, InvoiceDate=u'12/1/2010 8:26', UnitPrice=3.39, CustomerID=17850, Country=u'United Kingdom', day_of_week=u'Wednesday'),\n",
       " Row(InvoiceNo=u'536365', StockCode=u'84029E', Description=u'RED WOOLLY HOTTIE WHITE HEART.', Quantity=6, InvoiceDate=u'12/1/2010 8:26', UnitPrice=3.39, CustomerID=17850, Country=u'United Kingdom', day_of_week=u'Wednesday')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepped_df.limit(5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(InvoiceNo,StringType,true),StructField(StockCode,StringType,true),StructField(Description,StringType,true),StructField(Quantity,IntegerType,true),StructField(InvoiceDate,StringType,true),StructField(UnitPrice,DoubleType,false),StructField(CustomerID,IntegerType,true),StructField(Country,StringType,true),StructField(day_of_week,StringType,true)))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepped_df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split data into train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = prepped_df.randomSplit([0.8, 0.2], seed=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert string column values into numeric indexers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer()\\\n",
    "    .setInputCol(\"day_of_week\")\\\n",
    "    .setOutputCol(\"day_of_week_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder()\\\n",
    "    .setInputCol(\"day_of_week_index\")\\\n",
    "    .setOutputCol(\"day_of_week_encoded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## leverage vector assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vectorAssembler = VectorAssembler()\\\n",
    "    .setInputCols([\"UnitPrice\", \"Quantity\", \"day_of_week_encoded\"])\\\n",
    "    .setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up transformation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "transformationPipeline = Pipeline()\\\n",
    "    .setStages([indexer, encoder, vectorAssembler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transform training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "fittedPipeline = transformationPipeline.fit(train_df)\n",
    "transformed_train_df = fittedPipeline.transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(InvoiceNo=u'536365', StockCode=u'21730', Description=u'GLASS STAR FROSTED T-LIGHT HOLDER', Quantity=6, InvoiceDate=u'12/1/2010 8:26', UnitPrice=4.25, CustomerID=17850, Country=u'United Kingdom', day_of_week=u'Wednesday', day_of_week_index=3.0, day_of_week_encoded=SparseVector(5, {3: 1.0}), features=SparseVector(7, {0: 4.25, 1: 6.0, 5: 1.0})),\n",
       " Row(InvoiceNo=u'536365', StockCode=u'22752', Description=u'SET 7 BABUSHKA NESTING BOXES', Quantity=2, InvoiceDate=u'12/1/2010 8:26', UnitPrice=7.65, CustomerID=17850, Country=u'United Kingdom', day_of_week=u'Wednesday', day_of_week_index=3.0, day_of_week_encoded=SparseVector(5, {3: 1.0}), features=SparseVector(7, {0: 7.65, 1: 2.0, 5: 1.0})),\n",
       " Row(InvoiceNo=u'536365', StockCode=u'71053', Description=u'WHITE METAL LANTERN', Quantity=6, InvoiceDate=u'12/1/2010 8:26', UnitPrice=3.39, CustomerID=17850, Country=u'United Kingdom', day_of_week=u'Wednesday', day_of_week_index=3.0, day_of_week_encoded=SparseVector(5, {3: 1.0}), features=SparseVector(7, {0: 3.39, 1: 6.0, 5: 1.0})),\n",
       " Row(InvoiceNo=u'536365', StockCode=u'84029E', Description=u'RED WOOLLY HOTTIE WHITE HEART.', Quantity=6, InvoiceDate=u'12/1/2010 8:26', UnitPrice=3.39, CustomerID=17850, Country=u'United Kingdom', day_of_week=u'Wednesday', day_of_week_index=3.0, day_of_week_encoded=SparseVector(5, {3: 1.0}), features=SparseVector(7, {0: 3.39, 1: 6.0, 5: 1.0})),\n",
       " Row(InvoiceNo=u'536365', StockCode=u'84406B', Description=u'CREAM CUPID HEARTS COAT HANGER', Quantity=8, InvoiceDate=u'12/1/2010 8:26', UnitPrice=2.75, CustomerID=17850, Country=u'United Kingdom', day_of_week=u'Wednesday', day_of_week_index=3.0, day_of_week_encoded=SparseVector(5, {3: 1.0}), features=SparseVector(7, {0: 2.75, 1: 8.0, 5: 1.0}))]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_train_df.limit(5).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "e = LogisticRegression(featuresCol=\"features\", labelCol=\"label_col\", weightCol=\"class_weight\", regParam=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model over training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = e.fit(transformed_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make predictions over training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.transform(transformed_train_df)\n",
    "test_predictions = model.transform(transformed_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use multi class classification evaluator to evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label_col\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute various evaluation measures over training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = evaluator.evaluate(train_predictions, {evaluator.metricName: \"accuracy\"})\n",
    "train_f1 = evaluator.evaluate(train_predictions, {evaluator.metricName: \"f1\"})\n",
    "train_precision = evaluator.evaluate(train_predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "train_recall = evaluator.evaluate(train_predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "test_acc = evaluator.evaluate(test_predictions, {evaluator.metricName: \"accuracy\"})\n",
    "test_f1 = evaluator.evaluate(test_predictions, {evaluator.metricName: \"f1\"})\n",
    "test_precision = evaluator.evaluate(test_predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "test_recall = evaluator.evaluate(test_predictions, {evaluator.metricName: \"weightedRecall\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
